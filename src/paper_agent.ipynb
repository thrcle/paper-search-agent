{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langgraph elasticsearch openai python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \n",
    "from typing import TypedDict, Literal, List, Dict, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from openai import OpenAI\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# .env 로드\n",
    "load_dotenv()\n",
    "\n",
    "# --- OpenAI ---\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# --- Elasticsearch ---\n",
    "ES_HOST = os.getenv(\"ES_HOST\", \"localhost\")\n",
    "ES_PORT = int(os.getenv(\"ES_PORT\", \"9200\"))\n",
    "ES_USER = os.getenv(\"ES_USER\", \"elastic\")\n",
    "ES_PASSWORD = os.getenv(\"ES_PASSWORD\", \"changeme\")\n",
    "ES_INDEX = os.getenv(\"ES_INDEX\", \"papers_index\")\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts=[{\"host\": ES_HOST, \"port\": ES_PORT, \"scheme\": \"http\"}],\n",
    "    basic_auth=(ES_USER, ES_PASSWORD),\n",
    ")\n",
    "\n",
    "# 필드 이름\n",
    "TITLE_FIELD = \"title\"\n",
    "CONTENT_FIELD = \"content\"\n",
    "YEAR_FIELD = \"year\"\n",
    "CITATION_FIELD = \"citations\"\n",
    "EMBED_FIELD = \"embedding\"\n",
    "\n",
    "# 검색 설정\n",
    "TOP_K_SPARSE = 30\n",
    "TOP_K_DENSE = 30\n",
    "TOP_K_FINAL = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 정의 + 공통 llm/임베딩 함수 \n",
    "# 상태 정의\n",
    "UtterType = Literal[\"KEYWORD_TOPIC\", \"NL_TOPIC\", \"SPECIFIC_PAPER\"]\n",
    "SearchStrategy = Literal[\"sparse\", \"dense\", \"hybrid\"]\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    query_text: str\n",
    "    utterance_type: UtterType\n",
    "    search_strategy: SearchStrategy\n",
    "    keyword_hits: List[Dict[str, Any]]\n",
    "    semantic_hits: List[Dict[str, Any]]\n",
    "    top_papers: List[Dict[str, Any]]\n",
    "    answer: str\n",
    "\n",
    "# LLM / Embedding 헬퍼\n",
    "def call_llm_json(system_prompt: str, user_prompt: str) -> Dict[str, Any]:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    import json\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "def call_llm_text(system_prompt: str, user_prompt: str) -> str:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    emb = client.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=text,\n",
    "    )\n",
    "    return emb.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node 1 : classify_utterance \n",
    "def classify_utterance_agent(state: AgentState) -> AgentState:\n",
    "    query = state[\"query_text\"].strip()\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "너는 논문 검색 에이전트의 인텐트 분류기다.\n",
    "유저의 질의를 아래 세 유형 중 하나로 분류해라.\n",
    "\n",
    "- KEYWORD_TOPIC: 키워드 위주의 짧은 검색어\n",
    "- NL_TOPIC: 자연어 서술형 질문\n",
    "- SPECIFIC_PAPER: 특정 논문을 가리키는 질문\n",
    "\n",
    "반드시 JSON으로:\n",
    "{\"utterance_type\": \"...\"}\n",
    "\"\"\"\n",
    "    user_prompt = f\"질문: {query}\"\n",
    "    result = call_llm_json(system_prompt, user_prompt)\n",
    "    utter: UtterType = result.get(\"utterance_type\", \"NL_TOPIC\")\n",
    "\n",
    "    # state[\"utterance_type\"] = utter\n",
    "    # return state\n",
    "    return {\"utterance_type\": utter}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2 : strategy_agent\n",
    "def strategy_agent(state: AgentState) -> AgentState:\n",
    "    utter = state[\"utterance_type\"]\n",
    "\n",
    "    if utter == \"KEYWORD_TOPIC\":\n",
    "        strategy: SearchStrategy = \"sparse\"\n",
    "    elif utter == \"SPECIFIC_PAPER\":\n",
    "        strategy = \"hybrid\"\n",
    "    else:\n",
    "        strategy = \"hybrid\"\n",
    "\n",
    "    return {\"search_strategy\": strategy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node 3 : keyword_search_agent (BM25)\n",
    "def keyword_search_agent(state: AgentState) -> AgentState:\n",
    "    query = state[\"query_text\"]\n",
    "    strategy = state.get(\"search_strategy\", \"hybrid\")\n",
    "\n",
    "    if strategy not in (\"sparse\", \"hybrid\"):\n",
    "        return {\"keyword_hits\": []}\n",
    "\n",
    "    body = {\n",
    "        \"size\": TOP_K_SPARSE,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [TITLE_FIELD, CONTENT_FIELD],\n",
    "                \"type\": \"best_fields\",\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    resp = es.search(index=ES_INDEX, body=body)\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "\n",
    "    results = []\n",
    "    for h in hits:\n",
    "        src = h[\"_source\"]\n",
    "        results.append({\n",
    "            \"id\": h[\"_id\"],\n",
    "            \"score\": h[\"_score\"],\n",
    "            \"title\": src.get(TITLE_FIELD),\n",
    "            \"content\": src.get(CONTENT_FIELD),\n",
    "            \"year\": src.get(YEAR_FIELD),\n",
    "            \"citations\": src.get(CITATION_FIELD, 0),\n",
    "        })\n",
    "\n",
    "    return {\"keyword_hits\": results}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic_search_agent \n",
    "def semantic_search_agent(state: AgentState) -> AgentState:\n",
    "    query = state[\"query_text\"]\n",
    "    strategy = state.get(\"search_strategy\", \"hybrid\")\n",
    "\n",
    "    if strategy not in (\"dense\", \"hybrid\"):\n",
    "        return {\"semantic_hits\": []}\n",
    "\n",
    "    q_vec = get_embedding(query)\n",
    "    body = {\n",
    "        \"size\": TOP_K_DENSE,\n",
    "        \"knn\": {\n",
    "            \"field\": EMBED_FIELD,\n",
    "            \"query_vector\": q_vec,\n",
    "            \"k\": TOP_K_DENSE,\n",
    "            \"num_candidates\": 100,\n",
    "        },\n",
    "    }\n",
    "    resp = es.search(index=ES_INDEX, body=body)\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "\n",
    "    results = []\n",
    "    for h in hits:\n",
    "        src = h[\"_source\"]\n",
    "        results.append({\n",
    "            \"id\": h[\"_id\"],\n",
    "            \"score\": h[\"_score\"],\n",
    "            \"title\": src.get(TITLE_FIELD),\n",
    "            \"content\": src.get(CONTENT_FIELD),\n",
    "            \"year\": src.get(YEAR_FIELD),\n",
    "            \"citations\": src.get(CITATION_FIELD, 0),\n",
    "        })\n",
    "\n",
    "    return {\"semantic_hits\": results}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrf_fusion(\n",
    "    keyword_hits: List[Dict[str, Any]],\n",
    "    semantic_hits: List[Dict[str, Any]],\n",
    "    k: int = TOP_K_FINAL,\n",
    "    k_rrf: int = 60,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    scores = defaultdict(float)\n",
    "    docs: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    for rank, d in enumerate(keyword_hits):\n",
    "        doc_id = d[\"id\"]\n",
    "        scores[doc_id] += 1.0 / (k_rrf + rank + 1)\n",
    "        docs.setdefault(doc_id, d)\n",
    "\n",
    "    for rank, d in enumerate(semantic_hits):\n",
    "        doc_id = d[\"id\"]\n",
    "        scores[doc_id] += 1.0 / (k_rrf + rank + 1)\n",
    "        docs.setdefault(doc_id, d)\n",
    "\n",
    "    fused = sorted(docs.values(), key=lambda d: scores[d[\"id\"]], reverse=True)\n",
    "    return fused[:k]\n",
    "\n",
    "def merge_and_select_agent(state: AgentState) -> AgentState:\n",
    "    keyword_hits = state.get(\"keyword_hits\", [])\n",
    "    semantic_hits = state.get(\"semantic_hits\", [])\n",
    "\n",
    "    fused = rrf_fusion(keyword_hits, semantic_hits, k=TOP_K_FINAL)\n",
    "    state[\"top_papers\"] = fused\n",
    "\n",
    "    query = state[\"query_text\"]\n",
    "\n",
    "    if not fused:\n",
    "        state[\"answer\"] = \"관련 논문을 찾지 못했어. 검색어를 조금 더 구체적으로 바꿔볼래?\"\n",
    "        return state\n",
    "\n",
    "    papers_text = []\n",
    "    for i, p in enumerate(fused, start=1):\n",
    "        papers_text.append(\n",
    "            f\"{i}. 제목: {p.get('title')}\\n\"\n",
    "            f\"   연도: {p.get('year')}, 인용수: {p.get('citations')}\\n\"\n",
    "            f\"   내용: {p.get('content')[:400]}...\"\n",
    "        )\n",
    "    papers_block = \"\\n\\n\".join(papers_text)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "너는 논문 검색 어시스턴트다.\n",
    "사용자의 질문과 후보 논문 목록을 보고,\n",
    "- 중요한 3~5편을 골라 제목과 요약을 제시하고\n",
    "- 왜 관련 있는지 코멘트를 달아라.\n",
    "- 최신 논문이 있다면 우선 언급해라.\n",
    "\n",
    "한국어로, 핵심 위주로 설명해라.\n",
    "\"\"\"\n",
    "    user_prompt = f\"질문: {query}\\n\\n후보 논문 목록:\\n{papers_block}\"\n",
    "    answer = call_llm_text(system_prompt, user_prompt)\n",
    "    state[\"answer\"] = answer\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'papers_index': {'mappings': {'properties': {'abstract': {'type': 'text'}, 'citations': {'type': 'integer'}, 'content': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}, 'embedding': {'type': 'dense_vector', 'dims': 3072, 'index': True, 'similarity': 'cosine', 'index_options': {'type': 'int8_hnsw', 'm': 16, 'ef_construction': 100}}, 'title': {'type': 'text'}, 'url': {'type': 'keyword'}, 'venue': {'type': 'keyword'}, 'year': {'type': 'integer'}}}}}\n"
     ]
    }
   ],
   "source": [
    "from config import es, ES_INDEX\n",
    "print(es.indices.get_mapping(index=ES_INDEX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    workflow.add_node(\"classify_utterance_agent\", classify_utterance_agent)\n",
    "    workflow.add_node(\"strategy_agent\", strategy_agent)\n",
    "    workflow.add_node(\"keyword_search_agent\", keyword_search_agent)\n",
    "    workflow.add_node(\"semantic_search_agent\", semantic_search_agent)\n",
    "    workflow.add_node(\"merge_and_select_agent\", merge_and_select_agent)\n",
    "\n",
    "    workflow.set_entry_point(\"classify_utterance_agent\")\n",
    "\n",
    "    workflow.add_edge(\"classify_utterance_agent\", \"strategy_agent\")\n",
    "    workflow.add_edge(\"strategy_agent\", \"keyword_search_agent\")\n",
    "    workflow.add_edge(\"strategy_agent\", \"semantic_search_agent\")\n",
    "    workflow.add_edge(\"keyword_search_agent\", \"merge_and_select_agent\")\n",
    "    workflow.add_edge(\"semantic_search_agent\", \"merge_and_select_agent\")\n",
    "\n",
    "    workflow.set_finish_point(\"merge_and_select_agent\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "graph = build_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp.get(\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp.get(\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m), citations=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp.get(\u001b[33m'\u001b[39m\u001b[33mcitations\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 예시\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m최근 RAG retriever 설계 관련해서 중요한 논문 몇 개 알려줘\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mrun_query\u001b[39m\u001b[34m(q)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_query\u001b[39m(q: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m      2\u001b[39m     state: AgentState = {\u001b[33m\"\u001b[39m\u001b[33mquery_text\u001b[39m\u001b[33m\"\u001b[39m: q}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     result = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m질문:\u001b[39m\u001b[33m\"\u001b[39m, q)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[질의 유형]:\u001b[39m\u001b[33m\"\u001b[39m, result.get(\u001b[33m\"\u001b[39m\u001b[33mutterance_type\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI프로그래밍/paper_search_agent_project/venv_paper_agent/lib/python3.12/site-packages/langgraph/pregel/main.py:3050\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3048\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3050\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3051\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3055\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3056\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3058\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3059\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3062\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3063\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3064\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3065\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI프로그래밍/paper_search_agent_project/venv_paper_agent/lib/python3.12/site-packages/langgraph/pregel/main.py:2633\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2632\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2633\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2640\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI프로그래밍/paper_search_agent_project/venv_paper_agent/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI프로그래밍/paper_search_agent_project/venv_paper_agent/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI프로그래밍/paper_search_agent_project/venv_paper_agent/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI프로그래밍/paper_search_agent_project/venv_paper_agent/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mclassify_utterance_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclassify_utterance_agent\u001b[39m(state: AgentState) -> AgentState:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     query = \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m()\n\u001b[32m      5\u001b[39m     system_prompt = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m너는 논문 검색 에이전트의 인텐트 분류기다.\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m유저의 질의를 아래 세 유형 중 하나로 분류해라.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mutterance_type\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m}\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     16\u001b[39m     user_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m질문: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'strip'",
      "During task with name 'classify_utterance_agent' and id '80b6ea5a-1f96-9f97-6305-4b56782c8463'"
     ]
    }
   ],
   "source": [
    "def run_query(q: str):\n",
    "    state: AgentState = {\"query_text\": q}\n",
    "    result = graph.invoke(state)\n",
    "\n",
    "    print(\"질문:\", q)\n",
    "    print(\"\\n[질의 유형]:\", result.get(\"utterance_type\"))\n",
    "    print(\"[검색 전략]:\", result.get(\"search_strategy\"))\n",
    "    print(\"\\n[답변]\\n\", result.get(\"answer\"))\n",
    "\n",
    "    print(\"\\n[선택된 논문 리스트]\")\n",
    "    for i, p in enumerate(result.get(\"top_papers\", []), start=1):\n",
    "        print(f\"{i}. {p.get('title')} ({p.get('year')}), citations={p.get('citations')}\")\n",
    "\n",
    "# 예시\n",
    "run_query(\"최근 RAG retriever 설계 관련해서 중요한 논문 몇 개 알려줘\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_paper_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
