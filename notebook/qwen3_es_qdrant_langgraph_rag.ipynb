{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4625d575",
   "metadata": {},
   "source": [
    " <!-- # Qwen3 + Qwen Embedding + Elasticsearch + Qdrant + LangGraph í† ì´ RAG íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "\n",
    "- LLM: **Qwen3-8B-Instruct** (ë¡œì»¬ LLM, LM Studioì—ì„œ OpenAI í˜¸í™˜ ì„œë²„ë¡œ ì‹¤í–‰)\n",
    "- Embedding: **Qwen2.5-Embedding** (Hugging Face Transformers)\n",
    "- Sparse Search: **Elasticsearch (BM25)**\n",
    "- Dense Search: **Qdrant + Qwen2.5-Embedding**\n",
    "- Orchestration: **LangGraph StateGraph**\n",
    "- ì‹œë‚˜ë¦¬ì˜¤: *ê°„ë‹¨í•œ ë…¼ë¬¸ë“¤(ë”ë¯¸ ë°ì´í„°)ì„ ES/Qdrantì— ë„£ê³  â†’ LangGraph ì—ì´ì „íŠ¸ë¡œ ê²€ìƒ‰ + ìš”ì•½*\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb34e31",
   "metadata": {},
   "source": [
    "<!-- ## 0. ì‚¬ì „ ì¤€ë¹„ (ë…¸íŠ¸ë¶ ë°–ì—ì„œ í•  ì¼)\n",
    "\n",
    "### 0-1. Dockerë¡œ ES + Qdrant ì‹¤í–‰ (ì¶”ì²œ)\n",
    "\n",
    "`docker-compose.yml` ì˜ˆì‹œ (ë¡œì»¬ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì €ì¥):\n",
    "\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  es:\n",
    "    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.0\n",
    "    container_name: paper_search_es\n",
    "    environment:\n",
    "      - discovery.type=single-node\n",
    "      - xpack.security.enabled=false\n",
    "      - ES_JAVA_OPTS=-Xms1g -Xmx1g\n",
    "    ports:\n",
    "      - \"9200:9200\"\n",
    "\n",
    "  qdrant:\n",
    "    image: qdrant/qdrant:latest\n",
    "    container_name: paper_search_qdrant\n",
    "    ports:\n",
    "      - \"6333:6333\"\n",
    "```\n",
    "\n",
    "í„°ë¯¸ë„ì—ì„œ:\n",
    "ì—¬ëŸ¬ ê°œì˜ Docker ì»¨í…Œì´ë„ˆ(ì„œë¹„ìŠ¤)ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰\n",
    "ë„ì»¤ ì‹¤í–‰ = ì„œë²„ í•˜ë‚˜ë¥¼ ê¸°ë™í•´ì„œ ê·¸ ì•ˆì—ì„œ Elasticsearch ì„œë²„ê°€ ëŒì•„ê°€ê²Œ í•œë‹¤ëŠ” ì˜ë¯¸\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 0-2. LM Studioì—ì„œ Qwen3-8B-Instruct ì‹¤í–‰\n",
    "\n",
    "1. LM Studio ì„¤ì¹˜\n",
    "2. ëª¨ë¸ ë¸Œë¼ìš°ì €ì—ì„œ `Qwen3-8B-Instruct` (ë˜ëŠ” ë¹„ìŠ·í•œ ì´ë¦„ì˜ GGUF 4bit) ë‹¤ìš´ë¡œë“œ\n",
    "3. Server ëª¨ë“œë¡œ ì‹¤í–‰ (OpenAI í˜¸í™˜ API ëª¨ë“œ ì¼œê¸°)\n",
    "   - ê¸°ë³¸ ì£¼ì†Œ ì˜ˆì‹œ: `http://localhost:1234/v1`\n",
    "   - ëª¨ë¸ ì´ë¦„ì€ LM Studio UIì—ì„œ í™•ì¸ (ì˜ˆ: `qwen3-8b-instruct`)\n",
    "\n",
    " **LM Studio ì„œë²„ë¥¼ OpenAI í˜¸í™˜ API**ì²˜ëŸ¼ `requests`ë¡œ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ë°©ì‹ -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14010423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langgraph elasticsearch qdrant-client transformers accelerate sentencepiece requests typing-extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b1df2",
   "metadata": {},
   "source": [
    "<!-- ## 2. ê³µí†µ import ë° ìŠ¤í‚¤ë§ˆ ì •ì˜ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258e2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List, Optional, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import math\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0f3aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UtteranceType(str, Enum):\n",
    "    KEYWORD_TOPIC = \"keyword_topic\"         # í‚¤ì›Œë“œ ê¸°ë°˜ ì£¼ì œ ì§ˆì˜\n",
    "    NL_TOPIC = \"natural_language_topic\"     # ìì—°ì–´ ê¸°ë°˜ ì£¼ì œ ì§ˆì˜\n",
    "    SPECIFIC_PAPER = \"specific_paper\"       # íŠ¹ì • ë…¼ë¬¸ ì§€ëª©í˜•\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchStrategy:\n",
    "    utterance_type: UtteranceType\n",
    "    use_keyword_search: bool\n",
    "    use_semantic_abstract_search: bool\n",
    "    use_chunk_search: bool\n",
    "    keyword_weight: float\n",
    "    semantic_weight: float\n",
    "    relevance_weight: float\n",
    "    recency_weight: float\n",
    "    citation_weight: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Paper:\n",
    "    paper_id: str\n",
    "    title: str\n",
    "    abstract: str\n",
    "    year: Optional[int] = None\n",
    "    venue: Optional[str] = None\n",
    "    citations: Optional[int] = None\n",
    "    url: Optional[str] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PaperHit:\n",
    "    paper: Paper\n",
    "    score: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChunkHit:\n",
    "    paper_id: str\n",
    "    section: Optional[str]\n",
    "    chunk_id: str\n",
    "    text: str\n",
    "    score: float\n",
    "\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    # ì…ë ¥\n",
    "    query_text: str\n",
    "\n",
    "    # ë¶„ë¥˜/ì „ëµ\n",
    "    utterance_type: str\n",
    "    strategy: SearchStrategy\n",
    "\n",
    "    # ê²€ìƒ‰ ê²°ê³¼\n",
    "    keyword_hits: List[PaperHit]\n",
    "    semantic_hits: List[PaperHit]\n",
    "    merged_hits: List[PaperHit]\n",
    "    top_papers: List[PaperHit]\n",
    "    chunks: List[ChunkHit]\n",
    "\n",
    "    # ê¸°íƒ€ ì˜ì¡´ì„±\n",
    "    lm_client: Any\n",
    "\n",
    "    # ìµœì¢… ì¶œë ¥\n",
    "    answer: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47970631",
   "metadata": {},
   "source": [
    "<!-- ## 3. ë°œí™” ìœ í˜•ë³„ SearchStrategy ì„¤ì • -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61939422",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_STRATEGY_MAP: Dict[UtteranceType, SearchStrategy] = {\n",
    "    UtteranceType.KEYWORD_TOPIC: SearchStrategy(\n",
    "        utterance_type=UtteranceType.KEYWORD_TOPIC,\n",
    "        use_keyword_search=True,\n",
    "        use_semantic_abstract_search=True,\n",
    "        use_chunk_search=False,\n",
    "        keyword_weight=0.7,\n",
    "        semantic_weight=0.3,\n",
    "        relevance_weight=0.6,\n",
    "        recency_weight=0.2,\n",
    "        citation_weight=0.2,\n",
    "    ),\n",
    "    UtteranceType.NL_TOPIC: SearchStrategy(\n",
    "        utterance_type=UtteranceType.NL_TOPIC,\n",
    "        use_keyword_search=True,\n",
    "        use_semantic_abstract_search=True,\n",
    "        use_chunk_search=True,\n",
    "        keyword_weight=0.4,\n",
    "        semantic_weight=0.6,\n",
    "        relevance_weight=0.7,\n",
    "        recency_weight=0.15,\n",
    "        citation_weight=0.15,\n",
    "    ),\n",
    "    UtteranceType.SPECIFIC_PAPER: SearchStrategy(\n",
    "        utterance_type=UtteranceType.SPECIFIC_PAPER,\n",
    "        use_keyword_search=True,\n",
    "        use_semantic_abstract_search=False,\n",
    "        use_chunk_search=True,\n",
    "        keyword_weight=1.0,\n",
    "        semantic_weight=0.0,\n",
    "        relevance_weight=0.9,\n",
    "        recency_weight=0.05,\n",
    "        citation_weight=0.05,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066b7f0",
   "metadata": {},
   "source": [
    "<!-- ## 4. ES / Qdrant / Embedding / LLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì • -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ce8ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch í´ë¼ì´ì–¸íŠ¸ (Docker ê¸°ì¤€ localhost:9200)\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "\n",
    "# Qdrant í´ë¼ì´ì–¸íŠ¸ (Docker ê¸°ì¤€ localhost:6333)\n",
    "qdrant = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "# Qwen2.5 Embedding ëª¨ë¸ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œ â†’ ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŒ)\n",
    "EMBED_MODEL_NAME = \"BAAI/bge-m3\"  # í•„ìš” ì‹œ ë³€ê²½ ê°€ëŠ¥\n",
    "\n",
    "\n",
    "class QwenEmbedding:\n",
    "    def __init__(self, model_name: str = EMBED_MODEL_NAME, device: str = None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        # ì°¨ì› ìˆ˜ëŠ” ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¥´ì§€ë§Œ, Qwen2.5-Embeddingì€ ì¼ë°˜ì ìœ¼ë¡œ 1024 ë˜ëŠ” 1536 ê·¼ì²˜\n",
    "        # ì—¬ê¸°ì„œëŠ” runtimeì—ì„œ í™•ì¸í•´ë³¸ë‹¤.\n",
    "        dummy = self.encode([\"hello\"])\n",
    "        self.dim = dummy.shape[1]\n",
    "\n",
    "    def encode(self, texts: List[str]) -> Any:\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(\n",
    "                texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(self.device)\n",
    "            outputs = self.model(**inputs)\n",
    "            # ê°„ë‹¨íˆ mean pooling\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "            return embeddings.cpu().numpy()\n",
    "\n",
    "\n",
    "embedder = QwenEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dcd2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM Studio OpenAI í˜¸í™˜ ì„œë²„ìš© ê°„ë‹¨ LLM í´ë¼ì´ì–¸íŠ¸\n",
    "class LMStudioClient:\n",
    "    def __init__(self, base_url: str = \"http://localhost:1234/v1\", model: str = \"qwen3-8b-instruct\"):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.model = model\n",
    "\n",
    "    def chat(self, system_prompt: str, user_prompt: str) -> str:\n",
    "        url = f\"{self.base_url}/chat/completions\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            \"temperature\": 0.3,\n",
    "        }\n",
    "        resp = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "lm_client = LMStudioClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf77966e",
   "metadata": {},
   "source": [
    "<!-- ## 5. ES ì¸ë±ìŠ¤ & Qdrant ì»¬ë ‰ì…˜ ìƒì„± + ë”ë¯¸ ë…¼ë¬¸ ë°ì´í„° ì ì¬\n",
    "\n",
    "ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì— ë…¼ë¬¸ ë©”íƒ€ë°ì´í„°/ì´ˆë¡/ë³¸ë¬¸ì„ í¬ë¡¤ë§/ì „ì²˜ë¦¬í•´ì„œ ë„£ìœ¼ë©´ ëœë‹¤.  \n",
    "ì§€ê¸ˆì€ **3ê°œì˜ ë”ë¯¸ ë…¼ë¬¸**ë§Œ ì‚¬ìš©í•´ì„œ í”Œë¡œìš°ë¥¼ ë³´ì—¬ì¤€ë‹¤. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f705f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch ë²„ì „: (8, 14, 0)\n",
      "elastic-transport ë²„ì „: 8.17.1\n"
     ]
    }
   ],
   "source": [
    "import elasticsearch\n",
    "import elastic_transport\n",
    "\n",
    "print(\"elasticsearch ë²„ì „:\", elasticsearch.__version__)\n",
    "print(\"elastic-transport ë²„ì „:\", elastic_transport.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cde0d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from elasticsearch import Elasticsearch\n",
    "\n",
    "# es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# print(es.info())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "838dc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"papers_index\"\n",
    "VECTOR_COLLECTION = \"papers_abstract\"\n",
    "CHUNK_COLLECTION = \"papers_chunks\"\n",
    "\n",
    "\n",
    "def reset_es_index():\n",
    "    if es.indices.exists(index=INDEX_NAME):\n",
    "        es.indices.delete(index=INDEX_NAME)\n",
    "    es.indices.create(\n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"title\": {\"type\": \"text\"},\n",
    "                    \"abstract\": {\"type\": \"text\"},\n",
    "                    \"year\": {\"type\": \"integer\"},\n",
    "                    \"venue\": {\"type\": \"keyword\"},\n",
    "                    \"citations\": {\"type\": \"integer\"},\n",
    "                    \"url\": {\"type\": \"keyword\"},\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    print(\"[ES] index reset ì™„ë£Œ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d8c9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_qdrant_collections():\n",
    "    # Abstractìš© ì»¬ë ‰ì…˜\n",
    "    existing = [c.name for c in qdrant.get_collections().collections]\n",
    "    if VECTOR_COLLECTION in existing:\n",
    "        qdrant.delete_collection(VECTOR_COLLECTION)\n",
    "    qdrant.recreate_collection(\n",
    "        collection_name=VECTOR_COLLECTION,\n",
    "        vectors_config=VectorParams(size=embedder.dim, distance=Distance.COSINE),\n",
    "    )\n",
    "    # Chunkìš© ì»¬ë ‰ì…˜\n",
    "    existing = [c.name for c in qdrant.get_collections().collections]\n",
    "    if CHUNK_COLLECTION in existing:\n",
    "        qdrant.delete_collection(CHUNK_COLLECTION)\n",
    "    qdrant.recreate_collection(\n",
    "        collection_name=CHUNK_COLLECTION,\n",
    "        vectors_config=VectorParams(size=embedder.dim, distance=Distance.COSINE),\n",
    "    )\n",
    "    print(\"[Qdrant] collections reset ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "422e9661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë”ë¯¸ ë…¼ë¬¸ ë°ì´í„°\n",
    "dummy_papers = [\n",
    "    Paper(\n",
    "        paper_id=\"p1\",\n",
    "        title=\"Agentic RAG for Scientific Paper Search\",\n",
    "        abstract=\"We propose an agentic retrieval-augmented generation framework for scientific paper search ...\",\n",
    "        year=2024,\n",
    "        venue=\"NeurIPS\",\n",
    "        citations=50,\n",
    "        url=\"https://example.com/p1\",\n",
    "    ),\n",
    "    Paper(\n",
    "        paper_id=\"p2\",\n",
    "        title=\"Hybrid BM25 and Dense Retrieval for Academic Recommendation\",\n",
    "        abstract=\"This work combines sparse BM25 retrieval and dense embedding-based search for academic recommendations ...\",\n",
    "        year=2023,\n",
    "        venue=\"ICLR\",\n",
    "        citations=120,\n",
    "        url=\"https://example.com/p2\",\n",
    "    ),\n",
    "    Paper(\n",
    "        paper_id=\"p3\",\n",
    "        title=\"Self-Attention is All You Need\",\n",
    "        abstract=\"We introduce the Transformer architecture, based solely on self-attention mechanisms ...\",\n",
    "        year=2017,\n",
    "        venue=\"NIPS\",\n",
    "        citations=10000,\n",
    "        url=\"https://example.com/p3\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a87cde84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def ingest_dummy_data():\n",
    "    # ESì— ì¸ë±ì‹±\n",
    "    actions = []\n",
    "    for p in dummy_papers:\n",
    "        actions.append({\n",
    "            \"_index\": INDEX_NAME,\n",
    "            \"_id\": p.paper_id,\n",
    "            \"_source\": {\n",
    "                \"title\": p.title,\n",
    "                \"abstract\": p.abstract,\n",
    "                \"year\": p.year,\n",
    "                \"venue\": p.venue,\n",
    "                \"citations\": p.citations,\n",
    "                \"url\": p.url,\n",
    "            },\n",
    "        })\n",
    "    helpers.bulk(es, actions)\n",
    "    print(f\"[ES] {len(actions)}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ\")\n",
    "\n",
    "    # Qdrant: abstract ë²¡í„°\n",
    "    abstracts = [p.abstract for p in dummy_papers]\n",
    "    vecs = embedder.encode(abstracts)\n",
    "    points = []\n",
    "    for i, p in enumerate(dummy_papers):\n",
    "        points.append(\n",
    "            PointStruct(\n",
    "                id=i + 1,\n",
    "                vector=vecs[i].tolist(),\n",
    "                payload={\n",
    "                    \"paper_id\": p.paper_id,\n",
    "                    \"title\": p.title,\n",
    "                    \"abstract\": p.abstract,\n",
    "                    \"year\": p.year,\n",
    "                    \"venue\": p.venue,\n",
    "                    \"citations\": p.citations,\n",
    "                    \"url\": p.url,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    qdrant.upsert(collection_name=VECTOR_COLLECTION, points=points)\n",
    "    print(f\"[Qdrant] abstract vectors {len(points)}ê°œ ì—…ì„œíŠ¸ ì™„ë£Œ\")\n",
    "\n",
    "    # Qdrant: chunk ë²¡í„° (í† ì´: abstractë¥¼ chunkì²˜ëŸ¼ ì¬ì‚¬ìš©)\n",
    "    chunk_points = []\n",
    "    cid = 1\n",
    "    for p in dummy_papers:\n",
    "        text = f\"Core idea of {p.title}: {p.abstract}\"\n",
    "        vec = embedder.encode([text])[0]\n",
    "        chunk_points.append(\n",
    "            PointStruct(\n",
    "                id=cid,\n",
    "                vector=vec.tolist(),\n",
    "                payload={\n",
    "                    \"paper_id\": p.paper_id,\n",
    "                    \"section\": \"Intro\",\n",
    "                    \"chunk_id\": f\"{p.paper_id}_c1\",\n",
    "                    \"text\": text,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        cid += 1\n",
    "    qdrant.upsert(collection_name=CHUNK_COLLECTION, points=chunk_points)\n",
    "    print(f\"[Qdrant] chunk vectors {len(chunk_points)}ê°œ ì—…ì„œíŠ¸ ì™„ë£Œ\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba2049",
   "metadata": {},
   "source": [
    "<!-- ## 6. ì—ì´ì „íŠ¸ í•¨ìˆ˜ ì •ì˜ (ë°œí™” ë¶„ë¥˜, ì „ëµ, ê²€ìƒ‰, ë³‘í•©, chunk, ë‹µë³€) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04de1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_utterance_agent(state: AgentState) -> AgentState:\n",
    "    text = state[\"query_text\"].strip()\n",
    "\n",
    "    if \"ë…¼ë¬¸\" in text and (\"ì›ë³¸\" in text or \"ë³´ì—¬ì¤˜\" in text or \"ë§í¬\" in text):\n",
    "        utter = UtteranceType.SPECIFIC_PAPER\n",
    "    else:\n",
    "        tokens = text.split()\n",
    "        if len(tokens) <= 5 and any(k in text.lower() for k in [\"iclr\", \"neurips\", \"icml\", \"acl\", \"2023\", \"2024\", \"2025\"]):\n",
    "            utter = UtteranceType.KEYWORD_TOPIC\n",
    "        else:\n",
    "            utter = UtteranceType.NL_TOPIC\n",
    "\n",
    "    state[\"utterance_type\"] = utter.value\n",
    "    print(f\"[utterance] ë¶„ë¥˜ ê²°ê³¼: {utter.value}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def strategy_agent(state: AgentState) -> AgentState:\n",
    "    utter = UtteranceType(state[\"utterance_type\"])\n",
    "    strategy = SEARCH_STRATEGY_MAP[utter]\n",
    "    state[\"strategy\"] = strategy\n",
    "    print(f\"[strategy] ì „ëµ ì„ íƒ: {strategy}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93a4e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ES] index reset ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì œ ì‹¤í–‰\n",
    "reset_es_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f6e253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1l/ry5k1k8n3cb61x096k96f2fm0000gn/T/ipykernel_3280/4088941107.py:6: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant.recreate_collection(\n",
      "/var/folders/1l/ry5k1k8n3cb61x096k96f2fm0000gn/T/ipykernel_3280/4088941107.py:14: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Qdrant] collections reset ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "reset_qdrant_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4657bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ES] 3ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì™„ë£Œ\n",
      "[Qdrant] abstract vectors 3ê°œ ì—…ì„œíŠ¸ ì™„ë£Œ\n",
      "[Qdrant] chunk vectors 3ê°œ ì—…ì„œíŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ingest_dummy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9adddf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search_agent(state: AgentState) -> AgentState:\n",
    "    strategy = state[\"strategy\"]\n",
    "    if not strategy.use_keyword_search:\n",
    "        return state\n",
    "\n",
    "    q = state[\"query_text\"]\n",
    "    # ES multi_match\n",
    "    body = {\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": q,\n",
    "                \"fields\": [\"title^4\", \"abstract^2\", \"venue^1\"],\n",
    "                \"fuzziness\": \"AUTO\",\n",
    "            }\n",
    "        },\n",
    "        \"size\": 20,\n",
    "    }\n",
    "    resp = es.search(index=INDEX_NAME, body=body)\n",
    "    hits: List[PaperHit] = []\n",
    "    for h in resp[\"hits\"][\"hits\"]:\n",
    "        s = h[\"_source\"]\n",
    "        paper = Paper(\n",
    "            paper_id=h[\"_id\"],\n",
    "            title=s.get(\"title\", \"\"),\n",
    "            abstract=s.get(\"abstract\", \"\"),\n",
    "            year=s.get(\"year\"),\n",
    "            venue=s.get(\"venue\"),\n",
    "            citations=s.get(\"citations\"),\n",
    "            url=s.get(\"url\"),\n",
    "        )\n",
    "        hits.append(PaperHit(paper=paper, score=h[\"_score\"]))\n",
    "\n",
    "    hits.sort(key=lambda x: x.score, reverse=True)\n",
    "    state[\"keyword_hits\"] = hits\n",
    "    print(f\"[keyword] {len(hits)}ê°œ í›„ë³´ ë°œê²¬\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97e24fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search_agent(state: AgentState) -> AgentState:\n",
    "    strategy = state[\"strategy\"]\n",
    "    if not strategy.use_semantic_abstract_search:\n",
    "        return state\n",
    "\n",
    "    q_vec = embedder.encode([state[\"query_text\"]])[0]\n",
    "\n",
    "    results = qdrant.search(\n",
    "        collection_name=VECTOR_COLLECTION,\n",
    "        query_vector=q_vec.tolist(),\n",
    "        limit=20,\n",
    "    )\n",
    "    hits: List[PaperHit] = []\n",
    "    for r in results:\n",
    "        p = r.payload\n",
    "        paper = Paper(\n",
    "            paper_id=p[\"paper_id\"],\n",
    "            title=p[\"title\"],\n",
    "            abstract=p[\"abstract\"],\n",
    "            year=p.get(\"year\"),\n",
    "            venue=p.get(\"venue\"),\n",
    "            citations=p.get(\"citations\"),\n",
    "            url=p.get(\"url\"),\n",
    "        )\n",
    "        hits.append(PaperHit(paper=paper, score=r.score))\n",
    "\n",
    "    hits.sort(key=lambda x: x.score, reverse=True)\n",
    "    state[\"semantic_hits\"] = hits\n",
    "    print(f\"[semantic] {len(hits)}ê°œ í›„ë³´ ë°œê²¬\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c5f5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_select_agent(current_year: int = 2025):\n",
    "    def _agent(state: AgentState) -> AgentState:\n",
    "        strategy = state[\"strategy\"]\n",
    "        kw_hits = state.get(\"keyword_hits\", [])\n",
    "        sem_hits = state.get(\"semantic_hits\", [])\n",
    "\n",
    "        scores: Dict[str, float] = {}\n",
    "        meta: Dict[str, PaperHit] = {}\n",
    "\n",
    "        def add_scores(hits: List[PaperHit], weight: float, k_rrf: int = 60):\n",
    "            for rank, h in enumerate(hits, start=1):\n",
    "                pid = h.paper.paper_id\n",
    "                scores.setdefault(pid, 0.0)\n",
    "                scores[pid] += weight * (1.0 / (k_rrf + rank))\n",
    "                meta.setdefault(pid, h)\n",
    "\n",
    "        add_scores(kw_hits, strategy.keyword_weight)\n",
    "        add_scores(sem_hits, strategy.semantic_weight)\n",
    "\n",
    "        merged: List[PaperHit] = []\n",
    "        for pid, base in scores.items():\n",
    "            p = meta[pid].paper\n",
    "            recency = 0.0\n",
    "            if p.year:\n",
    "                delta = max(current_year - p.year, 0)\n",
    "                recency = 1 / (1 + delta)\n",
    "            cit = p.citations or 0\n",
    "            cit_score = math.log1p(cit) / 10.0\n",
    "\n",
    "            final = (\n",
    "                strategy.relevance_weight * base\n",
    "                + strategy.recency_weight * recency\n",
    "                + strategy.citation_weight * cit_score\n",
    "            )\n",
    "            merged.append(PaperHit(paper=p, score=final))\n",
    "\n",
    "        merged.sort(key=lambda x: x.score, reverse=True)\n",
    "        state[\"merged_hits\"] = merged\n",
    "\n",
    "        utter = UtteranceType(state[\"utterance_type\"])\n",
    "        top_n = 3 if utter == UtteranceType.SPECIFIC_PAPER else 5\n",
    "        state[\"top_papers\"] = merged[:top_n]\n",
    "        print(f\"[merge] top {top_n} ì„ íƒ: {[h.paper.title for h in state['top_papers']]}\")\n",
    "        return state\n",
    "\n",
    "    return _agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7307f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_retrieval_agent(state: AgentState) -> AgentState:\n",
    "    strategy = state[\"strategy\"]\n",
    "    if not strategy.use_chunk_search:\n",
    "        return state\n",
    "\n",
    "    top_papers = state.get(\"top_papers\", [])\n",
    "    if not top_papers:\n",
    "        return state\n",
    "\n",
    "    paper_ids = [h.paper.paper_id for h in top_papers]\n",
    "\n",
    "    # Qdrant filterë¡œ paper_id in paper_ids\n",
    "    # ë‹¨ìˆœ search + ì´í›„ í•„í„°ë§ (í† ì´ ë²„ì „)\n",
    "    q_vec = embedder.encode([state[\"query_text\"]])[0]\n",
    "    results = qdrant.search(\n",
    "        collection_name=CHUNK_COLLECTION,\n",
    "        query_vector=q_vec.tolist(),\n",
    "        limit=20,\n",
    "    )\n",
    "    chunks: List[ChunkHit] = []\n",
    "    for r in results:\n",
    "        p = r.payload\n",
    "        if p[\"paper_id\"] not in paper_ids:\n",
    "            continue\n",
    "        chunks.append(\n",
    "            ChunkHit(\n",
    "                paper_id=p[\"paper_id\"],\n",
    "                section=p.get(\"section\"),\n",
    "                chunk_id=p[\"chunk_id\"],\n",
    "                text=p[\"text\"],\n",
    "                score=r.score,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    chunks.sort(key=lambda x: x.score, reverse=True)\n",
    "    state[\"chunks\"] = chunks[:10]\n",
    "    print(f\"[chunk] {len(state['chunks'])}ê°œ chunk ì„ íƒ\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff95bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_agent(state: AgentState) -> AgentState:\n",
    "    strategy = state[\"strategy\"]\n",
    "    if not strategy.use_chunk_search:\n",
    "        # ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ëŠ” ì „ëµ\n",
    "        lines = [\"ì´ ì§ˆì˜ëŠ” ìš”ì•½ ëŒ€ì‹  ê´€ë ¨ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìš°ì„  ì œê³µí•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.\"]\n",
    "        for h in state.get(\"top_papers\", []):\n",
    "            lines.append(f\"- {h.paper.title} ({h.paper.year}, {h.paper.venue})\")\n",
    "        state[\"answer\"] = \"\\n\".join(lines)\n",
    "        print(\"[answer] chunk ë¯¸ì‚¬ìš© ì „ëµ â†’ ë¦¬ìŠ¤íŠ¸ë§Œ ìƒì„±\")\n",
    "        return state\n",
    "\n",
    "    top_papers = state.get(\"top_papers\", [])\n",
    "    chunks = state.get(\"chunks\", [])\n",
    "    if not top_papers:\n",
    "        state[\"answer\"] = \"ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\"\n",
    "        print(\"[answer] top_papers ì—†ìŒ\")\n",
    "        return state\n",
    "\n",
    "    paper_list_str = \"\\n\".join(\n",
    "        f\"- {h.paper.title} ({h.paper.year}, {h.paper.venue}) citationsâ‰ˆ{h.paper.citations}\"\n",
    "        for h in top_papers\n",
    "    )\n",
    "    context_str = \"\\n\\n\".join(\n",
    "        f\"[{ch.paper_id} - {ch.section}]\\n{ch.text}\" for ch in chunks\n",
    "    )\n",
    "\n",
    "    system_prompt = (\n",
    "        \"ë„ˆëŠ” ë…¼ë¬¸ ê²€ìƒ‰ ë° ìš”ì•½ì„ ë„ì™€ì£¼ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. \"\n",
    "        \"ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ ë…¼ë¬¸ ë³¸ë¬¸/ë©”íƒ€ ì •ë³´ë¥¼ ë³´ê³ , \"\n",
    "        \"ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ìš”ì•½ê³¼ ì¶”ì²œì„ ì œê³µí•´.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"\"\"ì‚¬ìš©ì ì§ˆë¬¸:\n",
    "{state[\"query_text\"]}\n",
    "\n",
    "ê´€ë ¨ ë…¼ë¬¸ ëª©ë¡:\n",
    "{paper_list_str}\n",
    "\n",
    "ë…¼ë¬¸ ë³¸ë¬¸ ë°œì·Œ:\n",
    "{context_str}\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "1. ì§ˆë¬¸ì— ëŒ€í•´ í•œ ë‹¨ë½ìœ¼ë¡œ í•µì‹¬ ìš”ì•½ì„ ë¨¼ì € ì‘ì„±í•´ì¤˜.\n",
    "2. ì´ì–´ì„œ ê° ë…¼ë¬¸ì´ ì´ ì£¼ì œì—ì„œ ì–´ë–¤ ê¸°ì—¬ë¥¼ í–ˆëŠ”ì§€ bulletë¡œ ì •ë¦¬í•´ì¤˜.\n",
    "3. ë§ˆì§€ë§‰ì— 'ì¶”ì²œ ë…¼ë¬¸' ì„¹ì…˜ì„ ë§Œë“¤ì–´, íŠ¹íˆ ë¨¼ì € ì½ìœ¼ë©´ ì¢‹ì€ ë…¼ë¬¸ 1~2í¸ì„ ê³¨ë¼ ì´ìœ ì™€ í•¨ê»˜ ì œì•ˆí•´ì¤˜.\n",
    "\"\"\"\n",
    "\n",
    "    lm: LMStudioClient = state[\"lm_client\"]\n",
    "    answer = lm.chat(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "    state[\"answer\"] = answer\n",
    "    print(\"[answer] LLM ìš”ì•½ ìƒì„± ì™„ë£Œ\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b1b44",
   "metadata": {},
   "source": [
    "<!-- ## 7. LangGraph ê·¸ë˜í”„ êµ¬ì„± ë° ì‹¤í–‰ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4079064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(current_year: int = 2025):\n",
    "    graph = StateGraph(AgentState)\n",
    "\n",
    "    graph.add_node(\"classify_utterance\", classify_utterance_agent)\n",
    "    graph.add_node(\"strategy\", strategy_agent)\n",
    "    graph.add_node(\"keyword_search\", keyword_search_agent)\n",
    "    graph.add_node(\"semantic_search\", semantic_search_agent)\n",
    "    graph.add_node(\"merge_and_select\", merge_and_select_agent(current_year=current_year))\n",
    "    graph.add_node(\"chunk_retrieval\", chunk_retrieval_agent)\n",
    "    graph.add_node(\"answer\", answer_agent)\n",
    "\n",
    "    graph.set_entry_point(\"classify_utterance\")\n",
    "    graph.add_edge(\"classify_utterance\", \"strategy\")\n",
    "    graph.add_edge(\"strategy\", \"keyword_search\")\n",
    "    graph.add_edge(\"keyword_search\", \"semantic_search\")\n",
    "    graph.add_edge(\"semantic_search\", \"merge_and_select\")\n",
    "    graph.add_edge(\"merge_and_select\", \"chunk_retrieval\")\n",
    "    graph.add_edge(\"chunk_retrieval\", \"answer\")\n",
    "    graph.add_edge(\"answer\", END)\n",
    "\n",
    "    app = graph.compile()\n",
    "    return app\n",
    "\n",
    "\n",
    "graph_app = build_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a6ed7f",
   "metadata": {},
   "source": [
    "<!-- ## 8. ì˜ˆì‹œ ì§ˆì˜ ì‹¤í–‰\n",
    "\n",
    "ì•„ë˜ ì˜ˆì‹œ ì§ˆì˜ë¥¼ ëŒë ¤ë³´ë©´ì„œ:\n",
    "\n",
    "- ë°œí™” ë¶„ë¥˜ ê²°ê³¼\n",
    "- ì „ëµ ì„ íƒ\n",
    "- ES / Qdrant ê²€ìƒ‰\n",
    "- ë³‘í•©/ë­í‚¹\n",
    "- chunk ì„ íƒ\n",
    "- Qwen3(LM Studio) ê¸°ë°˜ ìµœì¢… ë‹µë³€\n",
    "\n",
    "ê¹Œì§€ íë¦„ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f66156d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ì§ˆë¬¸: agentic rag ë…¼ë¬¸ ì¶”ì²œ\n",
      "[utterance] ë¶„ë¥˜ ê²°ê³¼: natural_language_topic\n",
      "[strategy] ì „ëµ ì„ íƒ: SearchStrategy(utterance_type=<UtteranceType.NL_TOPIC: 'natural_language_topic'>, use_keyword_search=True, use_semantic_abstract_search=True, use_chunk_search=True, keyword_weight=0.4, semantic_weight=0.6, relevance_weight=0.7, recency_weight=0.15, citation_weight=0.15)\n",
      "[keyword] 1ê°œ í›„ë³´ ë°œê²¬\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1l/ry5k1k8n3cb61x096k96f2fm0000gn/T/ipykernel_3280/1669883693.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = qdrant.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[semantic] 3ê°œ í›„ë³´ ë°œê²¬\n",
      "[merge] top 5 ì„ íƒ: ['Self-Attention is All You Need', 'Agentic RAG for Scientific Paper Search', 'Hybrid BM25 and Dense Retrieval for Academic Recommendation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1l/ry5k1k8n3cb61x096k96f2fm0000gn/T/ipykernel_3280/641953078.py:15: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = qdrant.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[chunk] 3ê°œ chunk ì„ íƒ\n",
      "[answer] LLM ìš”ì•½ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[ìµœì¢… ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸]\n",
      "- Self-Attention is All You Need 2017 NIPS https://example.com/p3\n",
      "- Agentic RAG for Scientific Paper Search 2024 NeurIPS https://example.com/p1\n",
      "- Hybrid BM25 and Dense Retrieval for Academic Recommendation 2023 ICLR https://example.com/p2\n",
      "\n",
      "[ìµœì¢… answer]\n",
      "\n",
      "â€œAgentic RAGâ€ëŠ” RAG(Retrieval-Augmented Generation)ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹œìŠ¤í…œì—ì„œ â€˜ì£¼ì²´(Ğ°Ğ³ĞµĞ½Ñ‚)â€™ê°€ ìŠ¤ìŠ¤ë¡œ ê²€ìƒ‰ ë° ìƒì„± ê³¼ì •ì„ íŒë‹¨í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ì‹ì„ ì˜ë¯¸í•˜ë©°, íŠ¹íˆ ê³¼í•™ ë…¼ë¬¸ ê²€ìƒ‰ ë“± ë³µì¡í•œ íƒìƒ‰ ì‘ì—…ì— ì ìš©ëœ ìµœì‹  ì—°êµ¬ì…ë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ì½ëŠ” ê²ƒ ì´ìƒì˜ â€˜í–‰ë™ ê¸°ë°˜â€™ ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ê´€ë ¨ ë…¼ë¬¸ ì¤‘ 2024ë…„ NeurIPSì—ì„œ ë°œí‘œëœ â€œAgentic RAG for Scientific Paper Searchâ€ëŠ” ì´ ì£¼ì œì˜ ìµœì‹  í•µì‹¬ ì—°êµ¬ë¡œ, 2023ë…„ ICLRì˜ â€œHybrid BM25 and Dense Retrieval for Academic Recommendationâ€ì€ RAGì˜ ì „í†µì  ì ‘ê·¼ë²•ì„ ë³´ì™„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, 2017ë…„ NIPSì˜ â€œSelf-Attention is All You Needâ€ì€ RAGì˜ ê¸°ì´ˆ ê¸°ìˆ ì¸ ë³€í˜•ëœ ì–´í…ì…˜ ê¸°ë°˜ ëª¨ë¸ë§ì„ ì œê³µí•˜ëŠ” ë…¼ë¬¸ì…ë‹ˆë‹¤.\n",
      "\n",
      "- **Agentic RAG for Scientific Paper Search (2024, NeurIPS)**: ì£¼ì²´ ê¸°ë°˜ì˜ RAG ì‹œìŠ¤í…œì„ ì œì•ˆí•˜ì—¬, ê³¼í•™ ë…¼ë¬¸ ê²€ìƒ‰ ì‹œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³ , ì ì ˆí•œ ì§ˆë¬¸ì„ ì¬ê²€ìƒ‰í•˜ê±°ë‚˜ ìƒì„±ì„ ì¬ì¡°ì •í•˜ëŠ” ëŠ¥ë ¥ì„ ê°€ì§„ â€˜ì£¼ì²´â€™ ì—­í• ì„ ìˆ˜í–‰í•¨ìœ¼ë¡œì¨, ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë” ì •í™•íˆ ì´í•´í•˜ê³  ì‘ë‹µì„ ìƒì„±í•¨.\n",
      "- **Hybrid BM25 and Dense Retrieval for Academic Recommendation** (2023, ICLR): RAGì˜ ê²€ìƒ‰ ë‹¨ê³„ì—ì„œ â€˜ìŠ¤í”„ë ˆìŠ¤â€™(BM25)ì™€ â€˜ë””ì¦ˆâ€™(Dense Retrieval)ë¥¼ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ê³ , ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì •ë°€ë„ë¥¼ í–¥ìƒì‹œí‚´. ì´ëŠ” RAGì˜ ê²€ìƒ‰ ë‹¨ê³„ì—ì„œì˜ â€˜ê²€ìƒ‰ ì „ëµâ€™ì„ ê°œì„ í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, Agentic RAGì™€ëŠ” ë‹¤ë¥´ê²Œ â€˜ì£¼ì²´â€™ê°€ ì•„ë‹Œ â€˜ê²€ìƒ‰ ì „ëµ ì¡°í•©â€™ì— ì´ˆì ì„ ë‘” ì—°êµ¬.\n",
      "- **Self-Attention is All You Need (2017, NIPS)**: RAGì˜ í•µì‹¬ ê¸°ë°˜ ê¸°ìˆ ë¡œ, Transformer ê¸°ë°˜ì˜ ì „ìš© ì–´í…ì…˜ ê¸°ë²•ì´ RAGì˜ ìƒì„± ëª¨ë¸(ì˜ˆ: GPT, LLaMA ë“±)ì— ë„ì…ë˜ì–´, í˜„ì¬ì˜ RAG ì‹œìŠ¤í…œì´ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” â€˜ê¸°ê³„ í•™ìŠµ ëª¨ë¸â€™ì˜ í•µì‹¬ êµ¬ì¡°ë¥¼ ì œê³µí•¨. Agentic RAGì˜ ìƒì„± ëª¨ë¸ì€ ì´ ë…¼ë¬¸ì˜ ê¸°ë°˜ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, â€˜ì£¼ì²´â€™ê°€ ìƒì„±ì„ ì¡°ì •í•˜ëŠ” ë°©ì‹ì€ ì´ ê¸°ìˆ ì˜ í™•ì¥ëœ í™œìš©ì…ë‹ˆë‹¤.\n",
      "\n",
      "**ì¶”ì²œ ë…¼ë¬¸**  \n",
      "1. **Agentic RAG for Scientific Paper Search (2024, NeurIPS)** â€” ì´ ë…¼ë¬¸ì€ â€˜ì£¼ì²´ ê¸°ë°˜ RAGâ€™ì˜ ìµœì‹  ì—°êµ¬ë¡œ, ê³¼í•™ì  ê²€ìƒ‰ì—ì„œì˜ â€˜í–‰ë™ ê¸°ë°˜â€™ ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì„ ì œì•ˆí•˜ë©°, Agentic RAGì˜ í•µì‹¬ ê°œë…ì„ ëª…í™•íˆ ì œì‹œí•©ë‹ˆë‹¤. íŠ¹íˆ, ê²€ìƒ‰ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³  ì¬ê²€ìƒ‰/ìƒì„± ì¡°ì •ì„ í•˜ëŠ” â€˜ì£¼ì²´â€™ ì—­í• ì´ í•µì‹¬ì´ë¯€ë¡œ, ì´ ì£¼ì œë¥¼ ì²˜ìŒ ì ‘í•˜ëŠ” ì—°êµ¬ìì—ê²Œ ê°€ì¥ ì í•©í•œ ì‹œì‘ì ì…ë‹ˆë‹¤.  \n",
      "2. **Self-Attention is All You Need (2017, NIPS)** â€” RAG ì‹œìŠ¤í…œì˜ ê¸°ì´ˆ ê¸°ìˆ ì„ ì œê³µí•˜ëŠ” ë…¼ë¬¸ìœ¼ë¡œ, Agentic RAGì˜ ìƒì„± ëª¨ë¸ì´ ê¸°ë°˜ìœ¼ë¡œ ë˜ëŠ” â€˜Transformer ê¸°ë°˜â€™ ëª¨ë¸ì˜ í•µì‹¬ì´ ì´ ë…¼ë¬¸ì…ë‹ˆë‹¤. Agentic RAGì„ ì´í•´í•˜ë ¤ë©´ ì´ ë…¼ë¬¸ì„ ë¨¼ì € ì½ëŠ” ê²ƒì´ í•„ìˆ˜ì…ë‹ˆë‹¤. ì´ëŠ” ê¸°ìˆ ì  ê¸°ë°˜ì„ ì´í•´í•˜ê¸° ìœ„í•œ í•„ìˆ˜ì ì¸ ë…¼ë¬¸ìœ¼ë¡œ, RAGì˜ êµ¬ì¡°ì™€ ìƒì„± ëª¨ë¸ì˜ ê¸°ë³¸ì„ ì´í•´í•˜ëŠ” ë° ìˆì–´ â€˜ê¸°ì´ˆâ€™ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "================================================================================\n",
      "ì§ˆë¬¸: í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì— ëŒ€í•œ ì¢‹ì€ ë…¼ë¬¸ì„ ì¶”ì²œí•´ì¤˜\n",
      "[utterance] ë¶„ë¥˜ ê²°ê³¼: natural_language_topic\n",
      "[strategy] ì „ëµ ì„ íƒ: SearchStrategy(utterance_type=<UtteranceType.NL_TOPIC: 'natural_language_topic'>, use_keyword_search=True, use_semantic_abstract_search=True, use_chunk_search=True, keyword_weight=0.4, semantic_weight=0.6, relevance_weight=0.7, recency_weight=0.15, citation_weight=0.15)\n",
      "[keyword] 0ê°œ í›„ë³´ ë°œê²¬\n",
      "[semantic] 3ê°œ í›„ë³´ ë°œê²¬\n",
      "[merge] top 5 ì„ íƒ: ['Self-Attention is All You Need', 'Agentic RAG for Scientific Paper Search', 'Hybrid BM25 and Dense Retrieval for Academic Recommendation']\n",
      "[chunk] 3ê°œ chunk ì„ íƒ\n",
      "[answer] LLM ìš”ì•½ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[ìµœì¢… ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸]\n",
      "- Self-Attention is All You Need 2017 NIPS https://example.com/p3\n",
      "- Agentic RAG for Scientific Paper Search 2024 NeurIPS https://example.com/p1\n",
      "- Hybrid BM25 and Dense Retrieval for Academic Recommendation 2023 ICLR https://example.com/p2\n",
      "\n",
      "[ìµœì¢… answer]\n",
      "\n",
      "í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì€ ëŒ€ê°œ ëª¨ë¸ì˜ í‘œí˜„ë ¥, ì •ë³´ ì¶”ì¶œ ëŠ¥ë ¥, ê·¸ë¦¬ê³  ìƒí™©ì— ë§ëŠ” ì‘ë‹µì˜ ì •í™•ì„±ê³¼ ê´€ë ¨ëœ ì£¼ì œë¡œ, ë³¸ ë…¼ë¬¸ ëª©ë¡ì€ ì´ ì£¼ì œì— ì§ì ‘ì ìœ¼ë¡œ ê¸°ì—¬í•˜ëŠ” ë…¼ë¬¸ì´ ì•„ë‹Œ, ê´€ë ¨ëœ ê¸°ìˆ ì  ì ‘ê·¼ë²•(Transformer, RAG, ê²€ìƒ‰-ê²€ìƒ‰ ê²°í•©)ì„ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ â€œí”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒâ€ì´ë¼ëŠ” í•µì‹¬ ì£¼ì œì— ì§ì ‘ì ìœ¼ë¡œ ê¸°ì—¬í•˜ëŠ” ë…¼ë¬¸ì€ ì´ ëª©ë¡ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ì°¾ì•„ë³´ê¸° ì–´ë µìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê° ë…¼ë¬¸ì€ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì‹œìŠ¤í…œì˜ êµ¬ì„± ìš”ì†Œ(ì˜ˆ: ëª¨ë¸ ì•„í‚¤í…ì²˜, ê²€ìƒ‰-ìƒì„± í†µí•©, ì •ë³´ ì¶”ì¶œ)ì„ ê°œì„ í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì— **ê°„ì ‘ì ìœ¼ë¡œ ê¸°ì—¬**í•©ë‹ˆë‹¤. íŠ¹íˆ, â€œSelf-Attention is All You Needâ€ëŠ” í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëª¨ë¸ì˜ ê¸°ë³¸ ì•„í‚¤í…ì²˜ë¥¼ ì œê³µí•˜ë©°, â€œAgentic RAGâ€ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ ìœ ì—°í•˜ê²Œ ì •ë³´ë¥¼ ì¡°í•©í•˜ëŠ” ë°©ì‹ì„ ì œì‹œí•˜ê³ , â€œHybrid BM25 and Dense Retrievalâ€ëŠ” í”„ë¡¬í”„íŠ¸ê°€ ë°›ëŠ” ì •ë³´ì˜ ì§ˆì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "- **Self-Attention is All You Need**ëŠ” Transformer ì•„í‚¤í…ì²˜ë¥¼ ì†Œê°œí•˜ë©°, í˜„ì¬ ëŒ€ë‹¤ìˆ˜ì˜ í”„ë¡¬í”„íŠ¸ ëª¨ë¸(ì˜ˆ: GPT, LLaMA)ì˜ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì˜ ê¸°ë°˜ì´ ë¨.  \n",
      "- **Agentic RAG**ëŠ” í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìƒì„± ì‹œìŠ¤í…œì—ì„œ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” ë°©ì‹ì„ ì œì‹œí•˜ë©°, í”„ë¡¬í”„íŠ¸ê°€ â€œì •ë³´ë¥¼ ì¡°í•©â€í•˜ë„ë¡ ìœ ë„í•¨ìœ¼ë¡œì¨ ì„±ëŠ¥ í–¥ìƒì— ê¸°ì—¬í•¨.  \n",
      "- **Hybrid BM25 and Dense Retrieval**ëŠ” í”„ë¡¬í”„íŠ¸ê°€ ë°›ëŠ” ì •ë³´ì˜ ì§ˆì„ ë†’ì´ê¸° ìœ„í•´ ê²€ìƒ‰ì„ ê°•í™”í•˜ëŠ” ë°©ì‹ì„ ì œì‹œí•˜ë©°, ì´ëŠ” í”„ë¡¬í”„íŠ¸ì˜ ì…ë ¥ ë°ì´í„° ì§ˆì„ ê°œì„ í•˜ëŠ” ë° ê¸°ì—¬í•¨.\n",
      "\n",
      "**ì¶”ì²œ ë…¼ë¬¸**  \n",
      "1. **Self-Attention is All You Need (2017, NIPS)**  \n",
      "   - **ì´ìœ **: í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëª¨ë¸ì˜ ê¸°ë³¸ ê¸°ìˆ ì„ ì œê³µí•˜ëŠ” ë…¼ë¬¸. í˜„ì¬ ëª¨ë“  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ í•µì‹¬ ê¸°ë°˜ì„ ì´ë£¨ë©°, í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì˜ â€˜ê¸°ì´ˆâ€™ë¥¼ ì œê³µí•¨. í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„í•  ë•Œ ê¸°ë³¸ì ì¸ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì´í•´í•˜ì§€ ì•Šìœ¼ë©´, í”„ë¡¬í”„íŠ¸ì˜ íš¨ê³¼ë¥¼ ìµœëŒ€í•œ ë°œíœ˜í•  ìˆ˜ ì—†ìŒ.  \n",
      "2. **Agentic RAG for Scientific Paper Search (2024, NeurIPS)**  \n",
      "   - **ì´ìœ **: í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìƒì„± ì‹œìŠ¤í…œì—ì„œ â€œì •ë³´ ì¡°í•©â€ì„ ìœ ë„í•˜ëŠ” ë°©ì‹ì„ ì œì‹œí•˜ë©°, ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì— ì§ì ‘ì ìœ¼ë¡œ ì ìš© ê°€ëŠ¥í•œ ë…¼ë¬¸. íŠ¹íˆ, â€œí”„ë¡¬í”„íŠ¸ê°€ ìœ ë„í•˜ëŠ” í–‰ë™â€ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, í”„ë¡¬í”„íŠ¸ì˜ ìœ ì—°ì„±ê³¼ ì •í™•ì„±ì„ ë†’ì´ëŠ” ë°©ì‹ì´ ë‹ë³´ì„.  \n",
      "\n",
      "ì´ ë‘ ë…¼ë¬¸ì€ í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì˜ í•µì‹¬ ê¸°ìˆ ì„ ì œê³µí•˜ë©°, íŠ¹íˆ â€œSelf-Attentionâ€ì€ ê¸°ì´ˆ, â€œAgentic RAGâ€ëŠ” ì‹¤ì œ ì ìš© ë°©ì‹ì„ ì œì‹œí•¨ìœ¼ë¡œì¨, í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì— ëŒ€í•œ ì´í•´ì™€ ì ìš©ì„ ë™ì‹œì— ë„ì™€ì£¼ëŠ” í•µì‹¬ ìë£Œì…ë‹ˆë‹¤.\n",
      "\n",
      "================================================================================\n",
      "ì§ˆë¬¸: self-attention ê´€ë ¨ ë…¼ë¬¸ ì•Œë ¤ì¤˜\n",
      "[utterance] ë¶„ë¥˜ ê²°ê³¼: natural_language_topic\n",
      "[strategy] ì „ëµ ì„ íƒ: SearchStrategy(utterance_type=<UtteranceType.NL_TOPIC: 'natural_language_topic'>, use_keyword_search=True, use_semantic_abstract_search=True, use_chunk_search=True, keyword_weight=0.4, semantic_weight=0.6, relevance_weight=0.7, recency_weight=0.15, citation_weight=0.15)\n",
      "[keyword] 1ê°œ í›„ë³´ ë°œê²¬\n",
      "[semantic] 3ê°œ í›„ë³´ ë°œê²¬\n",
      "[merge] top 5 ì„ íƒ: ['Self-Attention is All You Need', 'Agentic RAG for Scientific Paper Search', 'Hybrid BM25 and Dense Retrieval for Academic Recommendation']\n",
      "[chunk] 3ê°œ chunk ì„ íƒ\n",
      "[answer] LLM ìš”ì•½ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "[ìµœì¢… ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸]\n",
      "- Self-Attention is All You Need 2017 NIPS https://example.com/p3\n",
      "- Agentic RAG for Scientific Paper Search 2024 NeurIPS https://example.com/p1\n",
      "- Hybrid BM25 and Dense Retrieval for Academic Recommendation 2023 ICLR https://example.com/p2\n",
      "\n",
      "[ìµœì¢… answer]\n",
      "\n",
      "Self-Attentionì€ 2017ë…„ NIPSì—ì„œ ë°œí‘œëœ \"Self-Attention is All You Need\"ì—ì„œ ì²˜ìŒ ì œì•ˆëœ ë³€í™˜ê¸°(Transformer) ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ, ì‹œí€€ìŠ¤ ë‚´ ê° ìœ„ì¹˜ì˜ ìš”ì†Œê°€ ë‹¤ë¥¸ ìœ„ì¹˜ì˜ ìš”ì†Œì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •ë³´ë¥¼ ê°€ì¤‘ì¹˜ë¡œ í•™ìŠµí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, ìì—°ì–´ ì²˜ë¦¬ ë° ì‹œí€€ìŠ¤ ëª¨ë¸ë§ì— í˜ì‹ ì ì¸ ê¸°ì´ˆë¥¼ ì œê³µí–ˆìŠµë‹ˆë‹¤. ì´í›„ ì´ ë©”ì»¤ë‹ˆì¦˜ì€ RAG, ê²€ìƒ‰, ì¶”ì²œ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™•ì¥ë˜ì–´, íŠ¹íˆ 2024ë…„ NeurIPSì—ì„œ ì œì‹œëœ Agentic RAGëŠ” Self-Attention ê¸°ë°˜ì˜ ê²€ìƒ‰-ìƒì„± í†µí•© ëª¨ë¸ì„, 2pm23ë…„ ICLRì—ì„œ ì œì‹œëœ Hybrid BM25ì™€ Dense Retrievalì€ Self-Attentionì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë°€ë„í˜• ê²€ìƒ‰ì„ í™œìš©í•´ í•™ìˆ  ì¶”ì²œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, Self-Attentionì˜ ìœ ì—°í•œ ì ìš© ê°€ëŠ¥ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
      "\n",
      "- **Self-Attention is All You Need (2017, NIPS)**: Self-Attentionì„ ê¸°ë°˜ìœ¼ë¡œ í•œ Transformer ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆ, ì‹œí€€ìŠ¤ ëª¨ë¸ë§ì˜ ê¸°ì´ˆê°€ ë˜ë©°, ì´í›„ ëª¨ë“  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(ì˜ˆ: GPT, BERT, T5 ë“±)ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¡œ ìë¦¬ ì¡ìŒ.\n",
      "- **Hybrid BM25 and Dense Retrieval for Academic Recommendation (2023, ICLR)**: Self-Attention ê¸°ë°˜ì˜ ë°€ë„í˜• ê²€ìƒ‰(ì˜ˆ: Dense Retrieval)ì„ BM25ì™€ ê²°í•©í•˜ì—¬ í•™ìˆ  ì¶”ì²œ ì‹œìŠ¤í…œì„ ê°œì„ , Self-Attentionì´ ë¬¸ë§¥ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ë³´ì—¬ì¤Œ.\n",
      "- **Agentic RAG for Scientific Paper Search (2024, NeurIPS)**: Self-Attention ê¸°ë°˜ì˜ RAG ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ agentic ê²€ìƒ‰-ìƒì„± ì‹œìŠ¤í…œì„ ì œì•ˆ, Self-Attentionì´ ì§ˆë¬¸-ë¬¸ì„œ ìƒí˜¸ì‘ìš©ì—ì„œ ìœ ì—°í•œ ì •ë³´ ì¶”ì¶œì„ ê°€ëŠ¥í•˜ê²Œ í•¨ì„ ë³´ì—¬ì¤Œ.\n",
      "\n",
      "**ì¶”ì²œ ë…¼ë¬¸**  \n",
      "1. **Self-Attention is All You Need (2017, NIPS)** â€” *ì´ ë…¼ë¬¸ì€ Self-Attentionì´ ëª¨ë“  ì‹œí€€ìŠ¤ ëª¨ë¸ë§ì˜ í•µì‹¬ì´ ë˜ëŠ” ê²ƒì„ ì…ì¦í•˜ë©°, ì´í›„ ëª¨ë“  ëŒ€ê·œëª¨ ëª¨ë¸ì˜ ê¸°ì´ˆê°€ ë¨*  \n",
      "   â†’ Self-Attentionì´ ë¬´ì—‡ì¸ì§€, ì™œ í•„ìš”í•œì§€, ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ì— ëŒ€í•œ ìµœì´ˆì˜ ì²´ê³„ì  ì„¤ëª…ê³¼ ì‹¤í—˜ì„ í¬í•¨. ì´ë¡ ì  ê¸°ë°˜ì„ ì´í•´í•˜ë ¤ë©´ í•„ìˆ˜.\n",
      "2. **Hybrid BM25 and Dense Retrieval for Academic Recommendation (2023, ICLR)** â€” *Self-Attentionì´ ê²€ìƒ‰ ëª¨ë¸ì—ì„œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì‹¤ì œ ì ìš© ì‚¬ë¡€*  \n",
      "   â†’ Self-Attentionì´ ë°€ë„í˜• ê²€ìƒ‰ì—ì„œ ë¬¸ë§¥ì„ í•™ìŠµí•˜ëŠ” ë°©ì‹ì„ ë³´ì—¬ì£¼ëŠ” ì‹¤ì œ ì ìš©. ê¸°ìˆ ì  êµ¬í˜„ê³¼ ì„±ëŠ¥ ë¹„êµë¥¼ í¬í•¨.  \n",
      "   â†’ Self-Attentionì´ ê²€ìƒ‰/ì¶”ì²œ ë¶„ì•¼ì—ì„œì˜ ì—­í• ì„ ì´í•´í•˜ë ¤ë©´ ì´ ë…¼ë¬¸ì´ ìœ ìš©í•¨.\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    \"agentic rag ë…¼ë¬¸ ì¶”ì²œ\",\n",
    "    \"í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í–¥ìƒì— ëŒ€í•œ ì¢‹ì€ ë…¼ë¬¸ì„ ì¶”ì²œí•´ì¤˜\",\n",
    "    \"self-attention ê´€ë ¨ ë…¼ë¬¸ ì•Œë ¤ì¤˜\",\n",
    "]\n",
    "\n",
    "for q in examples:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ì§ˆë¬¸:\", q)\n",
    "    init_state: AgentState = {\n",
    "        \"query_text\": q,\n",
    "        \"lm_client\": lm_client,\n",
    "    }\n",
    "    final_state = graph_app.invoke(init_state)\n",
    "    print(\"\\n[ìµœì¢… ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸]\")\n",
    "    for h in final_state.get(\"top_papers\", []):\n",
    "        print(\"-\", h.paper.title, h.paper.year, h.paper.venue, h.paper.url)\n",
    "    print(\"\\n[ìµœì¢… answer]\\n\")\n",
    "    print(final_state.get(\"answer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c3712ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\n",
      "  \"id\": \"chatcmpl-6ueydxw5j3lugb9o237g5s\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1763389768,\n",
      "  \"model\": \"qwen/qwen3-vl-4b\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Hello! How can I assist you today? ğŸ˜Š\",\n",
      "        \"tool_calls\": []\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 20,\n",
      "    \"completion_tokens\": 12,\n",
      "    \"total_tokens\": 32\n",
      "  },\n",
      "  \"stats\": {},\n",
      "  \"system_fin\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "resp = requests.post(\n",
    "\n",
    "    \"http://localhost:1234/v1/chat/completions\",  # í¬íŠ¸ëŠ” LM Studioì— ë§ì¶° ìˆ˜ì •\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    data=json.dumps({\n",
    "        \"model\": \"ì—¬ê¸°ì— LM Studioì— ëœ¨ëŠ” ëª¨ë¸ ì´ë¦„\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"hi\"},\n",
    "        ],\n",
    "    }),\n",
    ")\n",
    "print(resp.status_code)\n",
    "print(resp.text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "168f2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_paper_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
